{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pathlib\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting progressbar\n",
      "  Downloading progressbar-2.3.tar.gz\n",
      "    Complete output from command python setup.py egg_info:\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"C:\\Users\\neil\\AppData\\Local\\Temp\\pip-build-bgan7r5t\\progressbar\\setup.py\", line 5, in <module>\n",
      "        import progressbar\n",
      "      File \"C:\\Users\\neil\\AppData\\Local\\Temp\\pip-build-bgan7r5t\\progressbar\\progressbar\\__init__.py\", line 59, in <module>\n",
      "        from progressbar.widgets import *\n",
      "      File \"C:\\Users\\neil\\AppData\\Local\\Temp\\pip-build-bgan7r5t\\progressbar\\progressbar\\widgets.py\", line 121, in <module>\n",
      "        class FileTransferSpeed(Widget):\n",
      "      File \"c:\\users\\neil\\anaconda3\\lib\\abc.py\", line 133, in __new__\n",
      "        cls = super().__new__(mcls, name, bases, namespace, **kwargs)\n",
      "    ValueError: 'format' in __slots__ conflicts with class variable\n",
      "    \n",
      "    ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Command \"python setup.py egg_info\" failed with error code 1 in C:\\Users\\neil\\AppData\\Local\\Temp\\pip-build-bgan7r5t\\progressbar\\\n"
     ]
    }
   ],
   "source": [
    "!conda install progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\neil\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "#import progressbar\n",
    "from keras.preprocessing.image import random_shear, random_zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose, Dense, Dropout, Flatten, Input, UpSampling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate, Add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(kaggle_folder_path):\n",
    "    \n",
    "    #This section will define all the starting paths that will be needed\n",
    "    stage1_train_path = os.path.join(kaggle_folder_path, \"stage1_train\")\n",
    "    stage1_test_path = os.path.join(kaggle_folder_path, \"stage1_test\")\n",
    "    #This builds paths to the augmented train data folders we want to create\n",
    "    train_data_augmentation_path = os.path.join(kaggle_folder_path, \"train_data_augmentation\")\n",
    "    image_train_augmentation_path = os.path.join(train_data_augmentation_path, \"image_train_augmentation\")\n",
    "    mask_train_augmentation_path = os.path.join(train_data_augmentation_path, \"mask_train_augmentation\")\n",
    "    #This builds paths to the augmented test data folders we want to create\n",
    "    test_data_augmentation_path = os.path.join(kaggle_folder_path, \"test_data_augmentation\")\n",
    "    image_test_augmentation_path = os.path.join(test_data_augmentation_path, \"image_test_augmentation\")\n",
    "    #This part does the actual building of the folders\n",
    "    if not os.path.exists(train_data_augmentation_path):\n",
    "        os.makedirs(train_data_augmentation_path)\n",
    "    if not os.path.exists(image_train_augmentation_path):\n",
    "        os.makedirs(image_train_augmentation_path)\n",
    "    if not os.path.exists(mask_train_augmentation_path):\n",
    "        os.makedirs(mask_train_augmentation_path)\n",
    "    if not os.path.exists(test_data_augmentation_path):\n",
    "       os.makedirs(test_data_augmentation_path) \n",
    "    if not os.path.exists(image_test_augmentation_path):\n",
    "        os.makedirs(image_test_augmentation_path)\n",
    "    \n",
    "    #Now start building the train folders up\n",
    "    for folder_train in os.listdir(stage1_train_path):\n",
    "        #os.listdir(path) will list the items in the directory\n",
    "        stage1_train_folder_path = \"%s\" % folder_train\n",
    "        stage1_train_folder_path = os.path.join(stage1_train_path, stage1_train_folder_path)\n",
    "        image_and_masks_train_path = os.path.join(stage1_train_folder_path, \"image_and_masks\")\n",
    "        if not os.path.exists(image_and_masks_train_path):\n",
    "            os.makedirs(image_and_masks_train_path)\n",
    "        for items_train in os.listdir(stage1_train_folder_path): \n",
    "            if items_train == \"images\":\n",
    "                stage1_train_folder_images_path =\"%s\" % items_train\n",
    "                stage1_train_folder_images_path = os.path.join(stage1_train_folder_path, stage1_train_folder_images_path)        \n",
    "                for images_train in os.listdir(stage1_train_folder_images_path):\n",
    "                    stage1_train_images_list_path = \"%s\" % images_train\n",
    "                    stage1_train_images_list_path = os.path.join(stage1_train_folder_images_path, stage1_train_images_list_path)\n",
    "                    original_img_train = cv2.imread(stage1_train_images_list_path,1)\n",
    "                    height_train,width_train,channels_train = np.shape(original_img_train)\n",
    "                move_image = os.path.join(image_and_masks_train_path, \"image.png\")\n",
    "                cv2.imwrite(move_image, original_img_train)    \n",
    "                                   \n",
    "            if items_train == \"masks\":\n",
    "                all_masks_train = np.zeros([height_train,width_train,channels_train],np.uint8)\n",
    "                #this creates a blank image to start with for the adding of masks\n",
    "                stage1_train_folder_mask_path = \"%s\" % items_train\n",
    "                stage1_train_folder_mask_path = os.path.join(stage1_train_folder_path, stage1_train_folder_mask_path)\n",
    "                for masks_train in os.listdir(stage1_train_folder_mask_path):\n",
    "                    stage1_train_masks_list_path = \"%s\" % masks_train\n",
    "                    stage1_train_masks_list_path = os.path.join(stage1_train_folder_mask_path, stage1_train_masks_list_path)\n",
    "                    single_train_mask = cv2.imread(stage1_train_masks_list_path,1)\n",
    "                    all_masks_train = cv2.add(all_masks_train, single_train_mask)\n",
    "                combined_masks_path = os.path.join(image_and_masks_train_path, \"combined_masks.png\")\n",
    "                #this will put all_masks_train image and save it into the file called combined_masks\n",
    "                cv2.imwrite(combined_masks_path, all_masks_train)\n",
    "    \n",
    "    #Now start building the test folders up\n",
    "    for folder_test in os.listdir(stage1_test_path):\n",
    "        #os.listdir(path) will list the items in the directory\n",
    "        stage1_test_folder_path = \"%s\" % folder_test\n",
    "        stage1_test_folder_path = os.path.join(stage1_test_path, stage1_test_folder_path)\n",
    "        image_and_masks_test_path = os.path.join(stage1_test_folder_path, \"image_and_masks\")\n",
    "        if not os.path.exists(image_and_masks_test_path):\n",
    "            os.makedirs(image_and_masks_test_path)\n",
    "        for items_test in os.listdir(stage1_test_folder_path): \n",
    "            if items_test == \"images\":\n",
    "                stage1_test_folder_images_path =\"%s\" % items_test\n",
    "                stage1_test_folder_images_path = os.path.join(stage1_test_folder_path, stage1_test_folder_images_path)        \n",
    "                for images_test in os.listdir(stage1_test_folder_images_path):\n",
    "                    stage1_test_images_list_path = \"%s\" % images_test\n",
    "                    stage1_test_images_list_path = os.path.join(stage1_test_folder_images_path, stage1_test_images_list_path)\n",
    "                    original_img_test = cv2.imread(stage1_test_images_list_path,1)\n",
    "                    height_test,width_test,channels_test = np.shape(original_img_test)\n",
    "                move_image = os.path.join(image_and_masks_test_path, \"image.png\")\n",
    "                cv2.imwrite(move_image, original_img_test)    \n",
    "                                   \n",
    "            if items_test == \"masks\":\n",
    "                all_masks_test = np.zeros([height_test,width_test,channels_test],np.uint8)\n",
    "                #this creates a blank image to start with for the adding of masks\n",
    "                stage1_test_folder_mask_path = \"%s\" % items_test\n",
    "                stage1_test_folder_mask_path = os.path.join(stage1_test_folder_path, stage1_test_folder_mask_path)\n",
    "                for masks_test in os.listdir(stage1_test_folder_mask_path):\n",
    "                    stage1_test_masks_list_path = \"%s\" % masks_test\n",
    "                    stage1_test_masks_list_path = os.path.join(stage1_test_folder_mask_path, stage1_test_masks_list_path)\n",
    "                    single_test_mask = cv2.imread(stage1_test_masks_list_path,1)\n",
    "                    all_masks_test = cv2.add(all_masks_test, single_test_mask)\n",
    "                combined_masks_path = os.path.join(image_and_masks_test_path, \"combined_masks.png\")\n",
    "                #this will put all_masks_test image and save it into the file called combined_masks\n",
    "                cv2.imwrite(combined_masks_path, all_masks_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data_tensor(kaggle_folder_path):    \n",
    "    #type in terminal to remove DS.Store\n",
    "    # sudo find / -name \".DS_Store\" -depth -exec rm {} \\;\n",
    "\n",
    "    image_tensor = []\n",
    "    mask_tensor = []\n",
    "\n",
    "    stage_1_train_path = os.path.join(kaggle_folder_path, \"stage1_train\")\n",
    "    #stage_1_train_path = re.sub(\".DS_Store\", \"\", stage_1_train_path)\n",
    "    print(stage_1_train_path)\n",
    "\n",
    "    for folder in os.listdir(stage_1_train_path):\n",
    "        images_and_masks_folder_path = \"%s\" % folder\n",
    "        images_and_masks_folder_path = os.path.join(stage_1_train_path, images_and_masks_folder_path, \"image_and_masks\")\n",
    "        print(images_and_masks_folder_path)\n",
    "        for file in os.listdir(images_and_masks_folder_path):\n",
    "            if file == \"combined_masks.png\":\n",
    "                mask_path = \"%s\" % file\n",
    "                mask_path = os.path.join(images_and_masks_folder_path, mask_path)\n",
    "                print(mask_path)\n",
    "                mask_img = cv2.imread(mask_path,1)         \n",
    "                resized_mask = cv2.resize(mask_img, (256,256))\n",
    "                mask_tensor.append(resized_mask)\n",
    "            else:\n",
    "                image_path = os.path.join(images_and_masks_folder_path, file)\n",
    "                print(image_path)\n",
    "                image_img = cv2.imread(image_path,1)         \n",
    "                resized_image = cv2.resize(image_img, (256,256))\n",
    "                image_tensor.append(resized_image)  \n",
    "    return image_tensor, mask_tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kaggle_data_augmentation(training_image_tensor, training_mask_tensor):\n",
    "    \n",
    "    augmented_image_tensor = []\n",
    "    augmented_mask_tensor = []\n",
    "    model = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as session:\n",
    "        with progressbar.ProgressBar(max_value=len(training_image_tensor)) as bar:\n",
    "            for number in range(1,len(training_image_tensor)):\n",
    "                #part where we augment the original images\n",
    "                #to  keep indexing cosistent will group image and mask togther\n",
    "                #rather than all images then all the masks.\n",
    "                image = training_image_tensor[number][:][:][:]\n",
    "                mask = training_mask_tensor[number][:][:][:]\n",
    "                imageT = tf.transpose(image, perm=[1, 0, 2])\n",
    "                maskT = tf.transpose(mask, perm=[1, 0, 2])\n",
    "                imageFUD = tf.image.flip_up_down(image)\n",
    "                maskFUD = tf.image.flip_up_down(mask)\n",
    "                imageR90 = tf.image.rot90(image,k=1,name=None)\n",
    "                maskR90 = tf.image.rot90(mask,k=1,name=None)\n",
    "                imageR270 = tf.image.rot90(image,k=3,name=None)\n",
    "                maskR270 = tf.image.rot90(mask,k=3,name=None)\n",
    "                imageAB = tf.image.adjust_brightness(image, delta=.5)\n",
    "                maskAB = tf.image.adjust_brightness(mask, delta=.5)\n",
    "                imageAC = tf.image.adjust_contrast(image, contrast_factor=.5)\n",
    "                maskAC = tf.image.adjust_contrast(mask, contrast_factor=.5)\n",
    "                imageAH = tf.image.adjust_hue(image, .5, name=None)\n",
    "                maskAH = tf.image.adjust_hue(mask, .5, name=None)\n",
    "                session.run(model)\n",
    "\n",
    "                #images_file_path = \"%s\" % number\n",
    "                #images_file_path = os.path.join(stage1_train_folder_images_path,images_file_path)\n",
    "                augmented_image_tensor.append(image)\n",
    "                imageT = session.run(imageT)\n",
    "                augmented_image_tensor.append(imageT)\n",
    "                imageFUD = session.run(imageFUD)\n",
    "                augmented_image_tensor.append(imageFUD)\n",
    "                imageR90 = session.run(imageR90)\n",
    "                augmented_image_tensor.append(imageR90)\n",
    "                imageR270 = session.run(imageR270)\n",
    "                augmented_image_tensor.append(imageR270)\n",
    "                imageAB = session.run(imageAB)\n",
    "                augmented_image_tensor.append(imageAB)\n",
    "                imageAC = session.run(imageAC)\n",
    "                augmented_image_tensor.append(imageAC)\n",
    "                imageAH = session.run(imageAH)\n",
    "                augmented_image_tensor.append(imageAH)\n",
    "                imageRS = random_shear(image, 2, row_axis=1, col_axis=2, channel_axis=0, fill_mode='nearest', cval=0.0)\n",
    "                augmented_image_tensor.append(imageRS)\n",
    "                imageRZ = random_zoom(image, [.9,.8], row_axis=1, col_axis=2, channel_axis=0, fill_mode='nearest', cval=0.0)\n",
    "                augmented_image_tensor.append(imageRZ)\n",
    "\n",
    "                augmented_mask_tensor.append(mask)    \n",
    "                maskT = session.run(maskT)\n",
    "                augmented_mask_tensor.append(maskT)\n",
    "                maskFUD = session.run(maskFUD)\n",
    "                augmented_mask_tensor.append(maskFUD)\n",
    "                maskR90 = session.run(maskR90)\n",
    "                augmented_mask_tensor.append(maskR90)\n",
    "                maskR270 = session.run(maskR270)\n",
    "                augmented_mask_tensor.append(maskR270)\n",
    "                maskAB = session.run(maskAB)\n",
    "                augmented_mask_tensor.append(maskAB)\n",
    "                maskAC = session.run(maskAC)\n",
    "                augmented_mask_tensor.append(maskAC)\n",
    "                maskAH = session.run(maskAH)\n",
    "                augmented_mask_tensor.append(maskAH)\n",
    "                maskRS = random_shear(mask, 2, row_axis=1, col_axis=2, channel_axis=0, fill_mode='nearest', cval=0.0)\n",
    "                augmented_mask_tensor.append(maskRS)\n",
    "                maskRZ = random_zoom(mask, [.9,.8], row_axis=1, col_axis=2, channel_axis=0, fill_mode='nearest', cval=0.0)\n",
    "                augmented_mask_tensor.append(maskRZ)\n",
    "                bar.update(number)\n",
    "    return  augmented_image_tensor, augmented_mask_tensor  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model starts here\n",
    "\n",
    "img_rows = 128\n",
    "img_cols = 128\n",
    "inputs = Input((img_rows, img_cols,3))\n",
    "x_train = np.random.random((100, 128, 128, 3))\n",
    "y_train = np.random.random((100, 128, 128, 1))\n",
    "x_test = np.random.random((20, 100, 100, 3))\n",
    "y_test = np.random.random((20, 100, 100, 1))\n",
    "\n",
    "conv1_0 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "conv1_1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1_0)\n",
    "conv1_2 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1_1)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1_2)\n",
    "\n",
    "conv2_0 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "conv2_1 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2_0)\n",
    "conv2_2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2_1)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2_2)\n",
    "\n",
    "conv3_0 = Conv2D(256, 4, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "conv3_1 = Conv2D(256, 4, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3_0)\n",
    "conv3_2 = Conv2D(256, 4, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3_1)\n",
    "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3_1)\n",
    "\n",
    "conv4_0 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "conv4_1 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4_0)\n",
    "drop4 = Dropout(0.5)(conv4_1)\n",
    "pool4 = MaxPooling2D(pool_size=(2, 2),padding = 'same')(drop4)\n",
    "\n",
    "conv5_0 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "conv5_1 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5_0)\n",
    "drop5 = Dropout(0.5)(conv5_1)\n",
    "\n",
    "up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "merge6 = Add()([drop4,up6])\n",
    "conv6_0 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "conv6_1 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6_0)\n",
    "\n",
    "up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6_1))\n",
    "merge7 = Add()([conv3_1,up7])\n",
    "conv7_0 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "conv7_1 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7_0)\n",
    "\n",
    "up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7_1))\n",
    "merge8 = Add()([conv2_1,up8])\n",
    "conv8_0 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "conv8_1 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8_0)\n",
    "\n",
    "up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8_1))\n",
    "merge9 = Add()([conv1_1,up9])\n",
    "conv9_0 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "conv9_1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9_0)\n",
    "conv9_2 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9_1)\n",
    "\n",
    "conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9_2)\n",
    "\n",
    "model = Model(input = inputs, output = conv10)\n",
    "model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=1, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
